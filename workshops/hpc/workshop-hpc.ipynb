{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIMRC Data Science Core Workshop on Using AHPCC\n",
    "\n",
    "- Link to [Google Drive Data folder](https://drive.google.com/drive/folders/1_IlfCe9hak_ggr7v2aydl-Zg21vIep3K?usp=sharing). Please download the `workshop-hpc-data` folder.\n",
    "- Link to [Github Repository](https://github.com/pv-is-nrt/aimrc-data-science-core). Please download the repository by going to Code (green button) > Download ZIP.\n",
    "- Link to [download PuTTY Installer](https://the.earth.li/~sgtatham/putty/latest/w64/putty-64bit-0.81-installer.msi) for Windows\n",
    "- Link to [download Fiji](https://downloads.imagej.net/fiji/latest/fiji-linux64.zip) for Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Here we go!\n",
    "\n",
    "In this exercise, you learned how to log into the Pinnacle Desktop and how to navigate the system. This exercise was done outside of the Jupyter notebook environment, of course.\n",
    "\n",
    "Make sure you\n",
    "1. Logged in to Pinnacle in your browser.\n",
    "2. Opened a Pinnacle Desktop and Jupyter Notebook session within your browser.\n",
    "3. Accessed Firefox browser within the Pinnacle Desktop session.\n",
    "4. Downloaded the `workshop-hpc-data` folder from the Google Drive link above.\n",
    "5. Downloaded the Github repository from the link above.\n",
    "6. Extracted both downloaded zip files to your home/downloads directory. Right click in the downloaded zip file and click on Extract Here.\n",
    "7. You are free to download/extract your files to any directory you prefer. But if you followed the instructions above, you Home/Downloads directory should look like this:\n",
    "    \n",
    "    ```bash\n",
    "    /home/username/Downloads/\n",
    "        ├── aimrc-data-science-core-main\n",
    "        ├── workshop-hpc-data\n",
    "        ├── aimrc-data-science-core-main.zip\n",
    "        └── workshop-hpc-data-20240725T******Z-001.zip\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Basic Shell Commands\n",
    "\n",
    "In this exercise, you will learn about logging into the Pinnacle server using SSH and running basic shell commands. You can use Windows Command Prompt for SSH or you can download and install PuTTY (link above). \n",
    "\n",
    "Type the following in Windows/Mac Command Prompt  \n",
    "`ssh username@hpc-portal2.hpc.uark.edu`\n",
    "\n",
    "Accept the certificate warning and enter your UARK password.\n",
    "\n",
    "Practice running the following commands\n",
    "```bash\n",
    "    - env\n",
    "    - who\n",
    "    - whoami\n",
    "    - hostname\n",
    "    - date\n",
    "    - df\n",
    "    - cd /home/username/Downloads\n",
    "    - ls -al\n",
    "```\n",
    "\n",
    "This exercise is done outside of the Jupyter notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: What have I gotten myself into?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get basic information about the hardware\n",
    "\n",
    "Run the following cells to get basic information about the system you are logged into using Python and from within a Jupyter environment, without needing to access the command line / shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import psutil that allows us to interact with the system processes\n",
    "import psutil\n",
    "\n",
    "# print the number of CPU cores available and the percent usage\n",
    "print(\"Number of CPU cores:\", psutil.cpu_count())\n",
    "print(\"CPU usage:\", psutil.cpu_percent(interval=1), \"%\")\n",
    "\n",
    "# print the total and used memory on the system\n",
    "memory = psutil.virtual_memory()\n",
    "print(\"Total memory:\", memory.total / (1024 * 1024 * 1024), \"GB\")\n",
    "print(\"Used memory:\", memory.used / (1024 * 1024 * 1024), \"GB\")\n",
    "\n",
    "# print the amount of GPU memory on the system\n",
    "gpu_memory = psutil.virtual_memory()\n",
    "print(\"Total GPU memory:\", gpu_memory.total / (1024 * 1024 * 1024), \"GB\")\n",
    "print(\"Used GPU memory:\", gpu_memory.used / (1024 * 1024 * 1024), \"GB\")\n",
    "\n",
    "# print the storage information on the system\n",
    "disk_partitions = psutil.disk_partitions()\n",
    "for d_p in disk_partitions:\n",
    "    print(\"Device: \" + d_p.device + \"; \"\n",
    "          \"Mountpoint: \" + d_p.mountpoint + \"; \"\n",
    "          \"File system type: \" + d_p.fstype)\n",
    "disk_usage = psutil.disk_usage('/')\n",
    "print(\"Total disk space:\", disk_usage.total / (1024 * 1024 * 1024), \"GB\")\n",
    "print(\"Used disk space:\", disk_usage.used / (1024 * 1024 * 1024), \"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get detailed information about the Nvidia GPU by using the nvidia-smi utility. This command will not work if the node does not have a dedicated Nvidia GPU.  \n",
    "Note that you can use shell commands in Jupyter Notebooks by prefixing the command with an exclamation mark (!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get information about the packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the list of packages installed in the current environment\n",
    "# !conda list # OR\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Running a simple Python program in Jupyter Notebook\n",
    "\n",
    "In this exercise, we will run a simple Python program in Jupyter Notebook. We write a program to crop images and save the cropped images in a new folder. We will use the images you already downloaded from the Google Drive link above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run if needed\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import PIL.Image as Image\n",
    "\n",
    "DATA_FOLDER = '/home/prateek/Downloads/workshop-hpc-data/NFFA images sampled'\n",
    "TARGET_FOLDER = '/home/prateek/Downloads/workshop-hpc-data/NFFA images sampled cropped'\n",
    "\n",
    "# Create target folder if it does not exist\n",
    "Path(TARGET_FOLDER).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of all files in the source folder\n",
    "files = list(Path(DATA_FOLDER).rglob('*.jpg'))\n",
    "print(len(files), 'total files found')\n",
    "\n",
    "# get the dimension of the first image\n",
    "img = Image.open(files[0])\n",
    "print('Dimensions of the first image:', img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cropping function\n",
    "def crop_image(file, data_folder, target_folder):\n",
    "    img = Image.open(file)\n",
    "    img = img.crop((0, 0, 1024, 600))\n",
    "    # save the cropped image in the target folder matching the subfolder structure\n",
    "    save_to_path = str(file).replace(data_folder, target_folder)\n",
    "    # make sure the subfolder exists\n",
    "    Path(save_to_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    img.save(save_to_path)\n",
    "    print('saved ' + save_to_path) # uncomment if you wish to see detailed output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop all images\n",
    "for file in files:\n",
    "    crop_image(file, DATA_FOLDER, TARGET_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Running jobs on the Pinnacle cluster\n",
    "\n",
    "In this exercise, we learn about submitting jobs to the Pinnacle server through the SSH terminal. This exercise is done outside of the Jupyter notebook environment. This batch job will run the Python script inspired from Exercise 4. You can see the python file and the corresponding batch script in the `workshops/hpc` directory.\n",
    "\n",
    "Make sure you:\n",
    "- delete the `NFFA images sampled cropped` folder if it exists in the `/home/USERNAME/Downloads/workshop-hpc-data/` directory\n",
    "- change into the /workshops/hpc directory  \n",
    "    `cd /home/USERNAME/Downloads/aimrc-data-science-core-main/workshops/hpc`\n",
    "- activate base environment  \n",
    "    `module list`  \n",
    "    `module load python/3.10-anaconda`  \n",
    "    `which python`  \n",
    "    `source /share/apps/bin/conda-3.10.sh`  \n",
    "- submit a Python script as a job    \n",
    "    `sinfo` observe the output   \n",
    "    `squeue` observe the output  \n",
    "    Run one of the following  \n",
    "    - `sbatch --partition pcon06 --constraint 'aimrc' --nodes=1 myjob.sh` OR  \n",
    "    - `sbatch --partition agpu06 --nodes=1 myjob.sh` OR  \n",
    "    - `sbatch --partition gpu72 --nodes=1 myjob.sh`\n",
    "- If your job is taking too long to start, you may want to cancel it and use another partition/constraint  \n",
    "    `squeue -u <yourusername>` will show only your jobs  \n",
    "    `scancel <jobid>`\n",
    "- Observe the `slurm-xxxxxx.out` file in the directory for script output (best observed through Jupyter)\n",
    "- Observe the `/home/USERNAME/Downloads/workshop-hpc-data/NFFA images sampled cropped/` directory for cropped images (best observed through Pinnacle Desktop) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Fiji\n",
    "\n",
    "In this exercise, we learn about logging into the Pinnacle Desktop, browsing the internet, downloading and installing Fiji and using Fiji to open and process image files.\n",
    "\n",
    "Make sure you:\n",
    "- Download (link at the top) and extract Fiji\n",
    "- Launch `ImageJ` executable file\n",
    "- Use one of the NFFA microscopy images to do an image processing of your choice in Fiji and save your result in your Documents folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: A machine learning experiment\n",
    "\n",
    "In this exercise, we write a simple machine learning program to classify images from the CIFAR10 dataset into ten categories. We will build and train a simple CNN model to classify the images. You will also learn to install any missing packages: These are installed into your home directory and you won't have to install them every time you log in.\n",
    "\n",
    "### NOTE: Please pick appropriate kernel \n",
    "In your Jupyter Notebook on Pinnacle, go to Kernel > Change Kernel and pick \"pytorch-cuda-3.14\" for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll probably need to install matplotlib and scipy for the first time\n",
    "!pip install matplotlib\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# try to suppress tensorflow warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# IGNORE TENSORFLOW WARNING IN RED for now. As long as the code finishes running, it's fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CIFAR-10 dataset from their website\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize some images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(6,7))\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a simple CNN model to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print(\"Test accuracy =\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Classification experiment on the NFFA SEM dataset\n",
    "\n",
    "You are welcome to try to run a classification experiment on the 250 microscope images (25 images per class) that you downloaded from the Google Drive link above. You can use the same CIFAR10 classification experiment as a template. You will need to modify the code to load the images and labels from the NFFA SEM dataset. Note that the performance may be poor because we only have 250 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the path to the data is still correct\n",
    "DATA_FOLDER = '/home/prateek/Downloads/workshop-hpc-data/NFFA images sampled'\n",
    "\n",
    "# prepare a training dataset from the images\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_FOLDER,\n",
    "    target_size=(1000, 750),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    # pick an appropriate class mode for 10 classes\n",
    "    class_mode='categorical')\n",
    "\n",
    "# print the class indices\n",
    "print(train_generator.class_indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some images from the first batch of training data\n",
    "image_batch, label_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(image_batch[i])\n",
    "    plt.xlabel(list(train_generator.class_indices.keys())[list(train_generator.class_indices.values()).index(label_batch[i].argmax())]) # there is probably a simpler way to do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new model appropriate for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple 3 layer CNN model\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(1000, 750, 3)))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_2.add(layers.MaxPooling2D((2, 2)))\n",
    "model_2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_2.add(layers.Flatten())\n",
    "model_2.add(layers.Dense(64, activation='relu'))\n",
    "model_2.add(layers.Dense(10, activation='softmax'))\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model_2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model_2.fit(train_generator, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for the first batch of images\n",
    "predictions = model_2.predict(image_batch)\n",
    "\n",
    "# visualize the predicted class for the predictions calculated above\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(image_batch[i])\n",
    "    plt.xlabel(list(train_generator.class_indices.keys())[predictions[i].argmax()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
